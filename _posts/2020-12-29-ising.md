---
title: "Classical Ising model with MCMC"
toc: true
toc_sticky: true
date: 2020-12-29 18:07:00
categories: 
  - Physics
tags: 
  - 2020-1.5
use_math: true
---

## Classical Ising model
Classical Ising model is briefly explained in <https://aadeliee22.github.io/physics/tsp-presentation/#classical-ising-model>.
This model is the simplest model of a magnet. Here, I will invest some special thermal properties of this model, with second-order phase transition and critical point.

## Background
Some thermodynamic and statistical backgrounds, as well as Monte Carlo methods.

First, by determining [Helmholtz free energy](https://en.wikipedia.org/wiki/Helmholtz_free_energy) of system $\mathcal{F} = -kT\ln Z$, we know that
$$
S = -\left(\frac{\partial \mathcal{F}}{\partial T}\right)_{V, N}, P = -\left(\frac{\partial \mathcal{F}}{\partial V}\right)_{T, N}, 
\mu = -\left(\frac{\partial \mathcal{F}}{\partial N}\right)_{T, V}
$$
Moreover, using these, we now obtain other quantities that may use as order parameters.
$$
U = -\frac{1}{Z}\frac{\partial Z}{\partial\beta} = -\frac{\partial}{\partial\beta}\ln Z = -T^2 \frac{\partial (\mathcal{F}/T)}{\partial T} = \langle E \rangle
\\ \begin{aligned} C &= T \frac{\partial S}{\partial T} = -\beta \frac{\partial S}{\partial \beta}= \frac{\partial U}{\partial T} 
= k\beta^2 \frac{\partial^2}{\partial \beta^2}\ln Z 
\\&=k\beta^2\left(\frac{1}{Z}\frac{\partial^2}{\partial\beta^2}Z - \left[ \frac{1}{Z}\frac{\partial}{\partial \beta}Z\right]^2\right) 
=k\beta^2(\langle E^2\rangle - \langle E\rangle^2) \end{aligned}
\\M = \frac{\partial \mathcal{F}}{\partial B} = \left\langle \sum_i s_i \right\rangle, \;\; \chi = \frac{\partial\langle M\rangle}{\partial B} 
= \beta (\langle M^2\rangle - \langle M \rangle ^2)
$$
where $U$ is internal energy, $C$ is specific heat capacity, and $M$ is magnetization, $\chi$ is magnetic susceptibility. 
Therefore, by knowing partition function, we could drive almost all quantities that we need.

### Some solution of classical Ising model
Mean field approximation of $d$-dimensional lattice is explained in <https://aadeliee22.github.io/physics/tsp-presentation/#mean-field-theory-for-d-dimensional-lattice>. 
Here, I will show exact solution for 1D lattice.

Consider 1-dimensional Ising model of periodic boundary that has $N$ sites. Given Hamiltonian, the partition function is
$$
\begin{aligned}
Z =& \sum_{\{\vec{s}\}}\exp(\beta J (s_1s_2 + \cdots + s_N s_1)+ \beta B(s_1+\cdots+s_N))
\\=& \sum_{\{\vec{s}\}}\exp(\beta J (s_1s_2 + \cdots + s_N s_1)+ \frac{1}{2}\beta B((s_1+s_2)+\cdots+(s_N+s_1))
\\=& \sum_{\{\vec{s}\}}\underbrace{\exp(\beta Js_1s_2+\frac{1}{2}\beta B(s_1+s_2))}_{\langle s_1|T|s_2\rangle}\cdots\underbrace{\exp(\beta Js_Ns_1+\frac{1}{2}\beta B(s_N+s_1))}_{\langle s_N|T|s_1\rangle}
\\=& \sum_{s_1}\cdots\sum_{s_N}\langle s_1|T|s_2\rangle\cdots\langle s_N|T|s_1\rangle = \sum_{s_1}\langle s_1|T|s_1\rangle = \text{Tr}(T^N) = \sum\lambda_i^N
\end{aligned}
$$

The $T$ part acts like a matrix, as each spin is either $1$ or $-1$. 
$$
T = \begin{array}{c|cc}s_i, s_{i+1}&+1 & -1 \\\hline
+1 & e^{\beta(J+B)} & e^{-\beta J}
\\-1 & e^{-\beta J} & e^{\beta(J-B)}
\end{array}
$$
This matrix has eigenvalue of 
$$
\lambda = e^{\beta J}\cosh \beta B\,\pm\sqrt{e^{2\beta J}\cosh^2\beta B-2\sinh2\beta J} 
$$
For $B=0$, $\lambda = e^{\beta J}\pm e^{-\beta J}$. Using this, we can calculate free energy and internal energy each.
$$
\mathcal{F} = -kT\ln Z = -\beta N\ln 2\cosh\beta J
\\ U = -\frac{\partial}{\partial \beta}\ln Z = -JN\tanh\beta J
$$

## Markov Chain Monte Carlo
Exact partition function is difficult to figure out, however, by statistical Monte Carlo simulations, it is able to solve it. Generally, we use a **Markov chain**. It requires careful design, as it must satisfy some properties.

### Markov Chain (MC)
The first-order Markov chain only depends on the last previous state(conditional probability) and can be described by transition function.
$$
p(x^{(k+1)}|x^{(1)}, \cdots,x^{(k)}) \equiv p(x^{(k+1)}|x^{(k)})\equiv T_k(x^{(k)}, x^{(k+1)}), \;\text{where }k\in 1, \cdots,M
$$
This chain is homogeneous if  $\forall i, j, \,T_i = T_j$.

A distribution is invariant/stationary when a transition function of the chain leaves the distribution unchanged, i.e.
$$
p^*(x) = \sum_{x'}T(x', x)p^*(x')
$$
Designing a transition operator that makes distribution stationary is important in our case. The transition operator satisfies **detailed balance** by
$$
p^*(x)T(x, x') = p^*(x')T(x', x)
$$
If this detailed balance is satisfied, the distribution is stationary under $T$.
Moreover, if the distribution $p(x^{(k)}|x^{(0)})\to p^*(x)$ (invariant) when $k\to\infty$, then the chain has property **ergodicity**. 
A poorly designed operator might divide a set into certain states. That is, the distribution can reach any state after a long time from any state. 

### Application: update method
In general, the transition operator from $a$ to $b$ is given by $T(a\to b) = A(a\to b)q(b|a)$.

#### Local update
Metropolis-Hastings algorithm is explained below.

We want to obtain $x^{(1)}\mapsto x^{(2)}\mapsto \cdots\mapsto x^{(m)}\cdots$. First, initialize, $\tau=1, \, x^{(\tau)}=?$

- Propose $x^{*}\sim q(x^{*}|x^{(\tau)})$
- Accept $x^*$ with an acceptance ratio $A(x^{(\tau)}\to x^*) = \min\left(1, \frac{p(x^*)q(x^{(\tau)}|x^*)}{p(x^{(\tau)})q(x^*|x^{(\tau)})}\right)$
- If accepted, $x^{(\tau+1)} = x^*$. Else, $x^{(\tau+1)} = x^{(\tau)}$.
- Repeat the above steps.

In our local update, a proposal is given by $q(b|a) = \text{constant}$. I'll briefly explain the scheme of this algorithm.
1. Define lattice size ($L$) and nearest-neighboring index. Initialize each spin site randomly or like chess-board; which has maximum energy level. (This will prevent super-cooling.) The nearest-neighboring index array will contain information of periodic boundary condition.
2. Define Monte-Carlo-one-step(**1 MC-step**) as following:
   * pick one spin site (randomly or checkerboard-style) and flip it. 
   * Calculate the energy difference ($=\Delta \mathcal{H}$).
   * If energy difference less than 0, accept the spin-flip. Else, accept it by the probability of $\exp(\Delta\mathcal{H}/kT)$. 
   * Perform the above steps for the whole spin site; which will be $L^2$.
3. Calculate important thermodynamic quantities:
   * Before calculation, perform 2000~2500 MC-steps to obtain an accurate value.
   * Calculate magnetization and energy for 10000 times. For each data, throw a few steps according to the autocorrelation time. 
   (e.g. Metropolis: $\theta \sim L^2$, Cluster: $\theta \sim L^{0.44}$) Without this throwing process, we will experience a certain bias of the observed value.
   * Calculate magnetization, magnetic susceptibility, energy, specific heat...etc.
4. Do the above steps for each temperature. Invest some quantities near the critical point.

#### Global update: Cluster update
Well-known local updates such as Metropolis update takes tremendous time and large autocorrelation between each state. We'll propose the most successful global update method, which is a cluster update. There are some fundamentals(**Fortuin-Kasteleyn cluster decomposition**) to discuss before explaining the algorithm.

First, let $\mathcal{H} = -\sum_{\langle i, j\rangle}s_is_j$ and $Z = \sum_{\{s\}}e^{-\beta \mathcal{H}}$. 
Remove interaction between fixed nearest-neighboring site of $\langle l, m\rangle$ : $\mathcal{H} _{l,m} = -\sum_{\langle i, j\rangle\neq \langle l, m\rangle} s_is_j$.

Define new partition function, considering rather $s_i, s_j$ are same or different.
$$
Z_{l, m}^{=}=\sum_{\{s\}}\delta_{s_l, s_m}e^{-\beta \mathcal{H}_{l, m}}, \; Z_{l, m}^{\neq}=\sum_{\{s\}}(1-\delta_{s_l, s_m})e^{-\beta\mathcal{H}_{l, m}}
$$

The original partition function is $Z = e^\beta Z_{l, m}^=+e^{-\beta}Z_{l, m}^\neq$. 
Moreover, define $Z_{l, m}^{indep.} = \sum e^{-\beta \mathcal{H}_{l,m}} = Z_{l,m}^=+Z_{l,m}^\neq$, then partition function $Z = (e^\beta-e^{-\beta})Z_{l,m}^=+e^{-\beta}Z_{l,m}^{indep.}$

Since $Z^=$ contains only when $s_l=s_m$, and $Z^{indep.}$ contains no restriction for spin-links, the weighing factors can be considered as probabilities of bond between site $l, m$. 
$$
p_{bond} = 1-e^{-2\beta}, \;Z = \sum p^b(1-p)^n 2^N
$$

By using the above probability, one can create a cluster for a simple Ising model.
I'll introduce **Wolff-cluster update**, which has proposal $q(b|a)/q(a|b) \equiv p(b)/p(a)$. (And has acceptance ratio $=1$.)
1. Choose a random site $i$, and select nearest-neighbor $j$.
2. If $s_i =s_j$, bond to cluster with probability $p = 1-e^{-2\beta J}$.
3. Repeat step 1 for site $j$, if it was in the cluster. Keep until no more bond is created.
4. Flip the entire cluster.

```c
// na = neighbor index array
int i = size*size * dis(gen);
int sp = 0, sh = 0;
double point;
double prob = 1 - exp(-2*J/T);
double oldspin = v[i], newspin = -v[i]; 
vector<int> stack(size*size, 0);
stack[0] = i; search[i] = 1; v[i] = newspin;
while (1) {
	for (int k = 0; k < 4; k++){
		point = na[i][k];
		if (v_[point] == oldspin && dis(gen) < prob) { 
			sh++; 
			stack.at(sh) = point;
			v[point] = newspin; 
		}
	}
}
```
